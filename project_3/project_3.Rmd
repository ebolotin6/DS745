---
title: "project_3"
author: "Eli (Ilya) Bolotin"
date: "11/14/2019"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r message=FALSE, warning=FALSE, include=FALSE}
if (!require("pacman")) install.packages("pacman")
pacman::p_load(keras, ggplot2)
```

## Dataset description

## Problem description/ Objective of the project

## Visually describe your textual data and findings

## Variables: identify relevant variables that are being usde in the analysis

## Methodology: steps detailing how the analysis was carried out

### Read in articles data and compute number of articles

```{r}
# read in articles
articles <- read.csv("nyt-comments/ArticlesApril2017.csv", header = T)
articles <- articles[,c("articleID","headline")]

# num unique articles
num_articles <- length(articles$articleID)
num_articles
```

### Read in comments data and select comment text and label

```{r}
# read in data
comments <- read.csv("nyt-comments/CommentsApril2017.csv", header = T)
comments <- comments[,c("commentBody","newDesk")]

# examine dataset size
dim_comments <- dim(comments)
total_comments <- dim_comments[1]
total_comments
```

### Get a count of classes (news desk) and preview comments and classes

```{r}
# preview comments
head(comments$commentBody)

# count unique classes
num_classes <- length(unique(comments$newDesk))
num_classes
```

For the month of April there were over 243,832 comments for `num_articles` articles

### Split comments into train and test sets

```{r}
set.seed(30)
num_train_samples <- round(total_comments * 0.80)
train_indices <- sample(1:total_comments, num_train_samples, replace = FALSE)
test_indices <- setdiff(1:num_train_samples, train_indices)
```

```{r}
# define x and y vars
x_train <- comments$commentBody[train_indices]
y_train <- comments$newDesk[train_indices]
x_test <- comments$commentBody[test_indices]
y_test <- comments$newDesk[test_indices]

# detach original data to clear memory
rm(comments)
```

### Tokenize text

Next, create a tokenizer that will map words to numbers.

```{r}
vocab_size = 30000
# create a tokenizer that maps words to numbers for every comment
tokenizer <- text_tokenizer(num_words = vocab_size) %>% fit_text_tokenizer(x_train)
```

### Examine tokenized data

```{r}
# Get total number of unique words from tokenizer
vocab_len <- length(tokenizer$word_index)
vocab_len

# View first/last word indices
head(tokenizer$word_index)
tail(tokenizer$word_index)
```

### Vectorize words

One-hot-coding every word for every comment (i.e. producing a binary word-vector for every word of every comment) is very computationally expensive. Instead, we can use an embedded layer in a neural network to represent the significance of word/sequences in the form of predetermined weights.

To do this, we need to vectorize every comment according to the tokenized word indices created above.

```{r}
# vectorize train and test data
train_vectors <- texts_to_sequences(tokenizer, x_train)
test_vectors <- texts_to_sequences(tokenizer, x_test)

# view embeddings
head(train_vectors)
```

### Pad tokenized sequences

Due to the fact that every sequence (comment) is of variable length, we need to standardize each sequence input before it can be fed to the neural network (which expects a fixed size input). This step involves:

* Determine the average length of comments
* Set a max sequence length, called the input_size
* For sequences less than max input size, pad these vectors with 0s.

```{r}
train_vector_lengths <- sapply(train_vectors, length)
hist(train_vector_lengths, main = "Train Vector Lengths Distribution")
quantiles = quantile(train_vector_lengths, probs = c(0.05, .95))
quantiles
```

As we can see above, the histogram contains a highly left-skewed distribution. We can see that length bottoms out near 300 words per comment (sequence). However, the 95% quantile is equal to `quantiles[2]` words per comment. So we can use this length as the input_size.

```{r}
# set input dimensions
vector_len = quantiles[2]

# Pad sequences
x_train <- pad_sequences(train_vectors, maxlen = vector_len, padding = "post")
x_test <- pad_sequences(test_vectors, maxlen = vector_len, padding = "post")

# View padded sequences
head(x_train)
```

### Create binary matrix from y_train

```{r}
y_train <- as.factor(y_train)
y_train_numeric <- as.numeric(y_train)-1
y_train_bin <- to_categorical(y_train_numeric, num_classes)
```


### Create Keras model

* Below, created embedding layer to represent vectorized words in compact form
* Arbitrarily chose to represent each vector in 50 dimensions (10 neurons)
* Create neural network layers

```{r}
# create model
model <- keras_model_sequential()

# define layers
model %>%
  layer_embedding(input_dim = vocab_len, output_dim = 100) %>%
  layer_global_average_pooling_1d() %>%  
  layer_dense(units = 50, activation = "relu") %>%
  layer_dropout(rate = 0.10) %>% 
  layer_dense(units = 40, activation = "relu") %>% 
  layer_dropout(rate = 0.10) %>% 
  layer_dense(units = num_classes, activation = "softmax")

# view summary
summary(model)

# view weights
# model$get_weights()
```

### Define gradient descent optimizer, loss function, and metrics

```{r}
model %>% compile(
  optimizer = 'adam',
  loss = 'categorical_crossentropy',
  metrics = 'accuracy'
)
```

### Train model 

```{r}
# create checkpoints folder to save model while training
checkpoint_dir <- "checkpoints"
dir.create(checkpoint_dir, showWarnings = FALSE)
filepath <- file.path(checkpoint_dir, "weights.{epoch:02d}-{val_loss:.2f}.hdf5")

# Create checkpoint callback
cp_callback <- callback_model_checkpoint(
  filepath = filepath,
  save_weights_only = TRUE,
  save_best_only = TRUE,
  verbose = 0
)

early_stopping <- callback_early_stopping(patience = 2)

# train model
history <- model %>% fit(
  x_train, y_train_bin, 
  epochs = 10, 
  batch_size = 128, 
  validation_split = 0.05,
  verbose = 1,
  callbacks = list(cp_callback, early_stopping)  # pass callback to training
)

model %>% save_model_hdf5("nyt_txt_class.h5")
```


### Plot model training

```{r}
plot(history)
```


### Evaluate model performance

```{r}
model %>% evaluate(x_test, y_test,verbose = 0)
```


### Generate predictions on new data

```{r}
model %>% predict_classes(x_test)
```


## Findings along with the discussion

## References (last page)